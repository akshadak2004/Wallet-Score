# -*- coding: utf-8 -*-
"""wallet score.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13DcCg-C65W_BLInRPdKJbzFUiyAhVzz-
"""

#POLYGONSCAN_API_KEY = "https://polished-quiet-flower.matic.quiknode.pro/c8def9ddc95529e92eba95b44d2899ef638c23ae/"

import csv
import json
import time
import requests
from uuid import uuid4

# ---- Configuration ----
  # Replace with your API key from polygonscan.com
NETWORK = "polygon"
OUTPUT_FILE = "all_wallet_transactions_polygon.json"

# Topic0 hashes (Keccak-256 of event signatures) for Compound/Aave actions
EVENT_TOPICS = {
    "deposit": "0xe1fffcc4923d2b0c0b7b2a9f4aa444b9b9f5b8b6ffb3c1a0ffb7e2d96e0f20fd",    # Mint (Deposit)
    "borrow": "0x13c7e01a83a7e20a84a2e41e6f7f257e5e2a5e6c3cb38cdd71d3b1e5d8bc7df6",     # Borrow
    "repay": "0x0e7527024b31ec6ccf5de30be8b3da8e1e6d6e476e97b8e97d7c6f39c9e5c4a7",      # RepayBorrow
    "liquidation": "0x3c1a1d5e6a3c49bfe2d95d4c5c1a1b7a0d8e8b5b37c7b8e37a5c2b6f7c8b7d8c" # LiquidationCall
}

BASE_URL = "https://api.polygonscan.com/api"

def build_tx(wallet, tx_hash, block_number, timestamp, action, amount="0", asset="MATIC", protocol="compound_v3"):
    return {
        "_id": {"$oid": str(uuid4())},
        "userWallet": wallet,
        "network": NETWORK,
        "protocol": protocol,
        "txHash": tx_hash,
        "logId": f"{tx_hash}_{action}",
        "timestamp": int(timestamp),
        "blockNumber": int(block_number),
        "action": action,
        "actionData": {
            "type": action,
            "amount": str(amount),
            "assetSymbol": asset,
            "assetPriceUSD": None,
            "poolId": None,
            "userId": wallet
        },
        "__v": 0,
        "createdAt": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "updatedAt": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
    }

def fetch_defi_logs(wallet):
    events = []
    for action, topic in EVENT_TOPICS.items():
        wallet_topic = "0x" + wallet.lower().replace("0x", "").rjust(64, "0")
        url = (
            f"{BASE_URL}?module=logs&action=getLogs"
            f"&fromBlock=0&toBlock=latest"
            f"&topic0={topic}&topic1={wallet_topic}"
            f"&apikey={POLYGONSCAN_API_KEY}"
        )
        try:
            res = requests.get(url).json()
            if res.get("status") == "1":
                for log in res["result"]:
                    tx_hash = log.get("transactionHash")
                    block_number = int(log.get("blockNumber", "0"), 16)
                    timestamp = int(log.get("timeStamp", "0"), 16) if "timeStamp" in log else 0
                    events.append(build_tx(wallet, tx_hash, block_number, timestamp, action))
        except Exception as e:
            print(f"Error fetching {action} for {wallet}: {e}")
        time.sleep(0.25)
    return events

def main():
    wallets = []
    with open("Wallet_id.csv", "r", newline='') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row.get("wallet_id"):
                wallets.append(row["wallet_id"].strip())

    all_events = []
    for wallet in wallets:
        print(f"Fetching DeFi actions on Polygon for {wallet}...")
        all_events.extend(fetch_defi_logs(wallet))

    with open(OUTPUT_FILE, "w") as f:
        json.dump(all_events, f, indent=2)

    print(f"\nCollected {len(all_events)} DeFi transactions from {len(wallets)} wallets (Polygon).")
    print(f"Results saved to {OUTPUT_FILE}")

if __name__ == "__main__":
    main()

import csv
import json
import time
import requests
from uuid import uuid4

# ---- Configuration ----
POLYGONSCAN_API_KEY = "YOUR_POLYGONSCAN_API_KEY"  # Replace with your Polygonscan API key
NETWORK = "polygon"
OUTPUT_FILE = "all_wallet_transactions_polygon.json"

def build_tx(wallet, tx, action="transfer", asset="MATIC"):
    """Format each transaction to the required structure."""
    timestamp = int(tx.get("timeStamp", 0))
    block_number = int(tx.get("blockNumber", 0))
    tx_hash = tx.get("hash")

    return {
        "_id": {"$oid": str(uuid4())},
        "userWallet": wallet,
        "network": NETWORK,
        "protocol": "polygonscan",
        "txHash": tx_hash,
        "logId": f"{tx_hash}_{action}",
        "timestamp": timestamp,
        "blockNumber": block_number,
        "action": action,
        "actionData": {
            "type": action,
            "amount": tx.get("value", "0"),
            "assetSymbol": asset,
            "assetPriceUSD": None,
            "poolId": None,
            "userId": wallet
        },
        "__v": 0,
        "createdAt": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "updatedAt": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
    }

def fetch_transactions(wallet):
    """Fetch all MATIC (Polygon) transactions for a wallet using Polygonscan API."""
    url = f"https://api.polygonscan.com/api?module=account&action=txlist&address={wallet}&startblock=0&endblock=99999999&sort=asc&apikey={POLYGONSCAN_API_KEY}"
    res = requests.get(url).json()
    return res["result"] if res.get("status") == "1" else []

def main():
    wallets = []

    # Read wallets from CSV (expects a header: wallet_id)
    with open("Wallet_id.csv", "r", newline='') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row.get("wallet_id"):
                wallets.append(row["wallet_id"].strip())

    all_transactions = []

    # Process each wallet
    for wallet in wallets:
        print(f"\nFetching Polygon transactions for {wallet}...")
        txs = fetch_transactions(wallet)
        for tx in txs:
            action = "transfer" if int(tx["value"]) > 0 else "contract_call"
            all_transactions.append(build_tx(wallet, tx, action, asset="MATIC"))
        time.sleep(0.5)  # Avoid hitting Polygonscan API limits

    # Save all results to one JSON file
    with open(OUTPUT_FILE, "w") as f:
        json.dump(all_transactions, f, indent=2)

    print(f"\nFetched {len(all_transactions)} total Polygon transactions.")
    print(f"Saved to {OUTPUT_FILE}")

if __name__ == "__main__":
    main()

import csv
import json
import time
import requests
from uuid import uuid4

# ---- Configuration ----
ETHERSCAN_API_KEY = "ZJMIAFTSXZUT51N1CMBQCXNN396HEP5J6W"
NETWORK = "ethereum"
OUTPUT_FILE = "all_wallet_transactions.json"

def build_tx(wallet, tx, action="transfer", asset="ETH"):
    """Format each transaction to the required structure."""
    timestamp = int(tx.get("timeStamp", 0))
    block_number = int(tx.get("blockNumber", 0))
    tx_hash = tx.get("hash")

    return {
        "_id": {"$oid": str(uuid4())},
        "userWallet": wallet,
        "network": NETWORK,
        "protocol": "etherscan",
        "txHash": tx_hash,
        "logId": f"{tx_hash}_{action}",
        "timestamp": timestamp,
        "blockNumber": block_number,
        "action": action,
        "actionData": {
            "type": action,
            "amount": tx.get("value", "0"),
            "assetSymbol": asset,
            "assetPriceUSD": None,
            "poolId": None,
            "userId": wallet
        },
        "__v": 0,
        "createdAt": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "updatedAt": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
    }

def fetch_transactions(wallet):
    """Fetch all ETH transactions for a wallet using Etherscan API."""
    url = f"https://api.etherscan.io/api?module=account&action=txlist&address={wallet}&startblock=0&endblock=99999999&sort=asc&apikey={ETHERSCAN_API_KEY}"
    res = requests.get(url).json()
    return res["result"] if res.get("status") == "1" else []

def main():
    wallets = []

    # Read wallets from CSV (expects a header: wallet_id)
    with open("Wallet_id.csv", "r", newline='') as f:
        reader = csv.DictReader(f)
        for row in reader:
            if row.get("wallet_id"):
                wallets.append(row["wallet_id"].strip())

    all_transactions = []

    # Process each wallet
    for wallet in wallets:
        print(f"\nFetching transactions for {wallet}...")
        txs = fetch_transactions(wallet)
        for tx in txs:
            action = "transfer" if int(tx["value"]) > 0 else "contract_call"
            all_transactions.append(build_tx(wallet, tx, action))
        time.sleep(0.5)  # Avoid API rate limit

    # Save all results to one JSON file
    with open(OUTPUT_FILE, "w") as f:
        json.dump(all_transactions, f, indent=2)

    print(f"\nFetched {len(all_transactions)} total transactions.")
    print(f"Saved to {OUTPUT_FILE}")

if __name__ == "__main__":
    main()

import pandas as pd
import json

# Step 1: Load the cleaned JSON file
with open('all_wallet_transactions.json', 'r') as f:
    data = json.load(f)

len(data)

print(data[0:2])

import pprint
pprint.pprint(data[0:2])

#check the length of all dictionries
from collections import Counter
Counter([len(items) for items in data])

df = pd.DataFrame(data)

df.columns

df.describe()

df.isnull().sum()

wallet_unique = df['userWallet'].nunique()
print(wallet_unique)

wallet_counts = df['userWallet'].value_counts()

one_tx_wallets = wallet_counts[wallet_counts == 1].index.tolist()
many_tx_wallets = wallet_counts[wallet_counts > 1].index.tolist()
no_tx =wallet_counts[wallet_counts == 0].index.tolist()

print("Transaction Categories:")
print(f"One transaction only: {len(one_tx_wallets)} wallets")
print(f"Many transactions:{len(many_tx_wallets)} wallets")
print(f"No transactions: {len(no_tx)} wallets")

def calculate_usd(row):
    try:
        amount = float(row['actionData']['amount'])
        price = float(row['actionData'].get('assetPriceUSD', 1))
        # Heuristically normalize token units (many tokens use 18 decimals)
        normalized_amount = amount / 1e18
        return normalized_amount * price
    except:
        return 0

df['usd_value'] = df.apply(calculate_usd, axis=1)

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# Load your dataset (update path to your JSON file)
df = pd.read_json('all_wallet_transactions.json')

# Convert timestamp
df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')

# Extract amounts from nested dict
def extract_amount(row):
    try:
        return float(row.get('amount', 0))
    except:
        return 0

df['amount'] = df['actionData'].apply(extract_amount)

# Flags for activity types (instead of DeFi-specific ones)
df['is_transfer'] = df['action'] == 'transfer'
df['is_contract'] = df['action'] == 'contract_call'

# Aggregate by wallet
agg_df = df.groupby('userWallet').agg(
    num_transfers=('is_transfer', 'sum'),
    num_contract_calls=('is_contract', 'sum'),
    total_volume_eth=('amount', 'sum'),
    tx_count=('action', 'count'),
    active_days=('timestamp', lambda x: x.dt.date.nunique())
).reset_index()

# Scale features
X = agg_df.drop(columns=['userWallet'])
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Cluster wallets into 4 segments
kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
agg_df['cluster'] = kmeans.fit_predict(X_scaled)

# Summarize clusters
numeric_cols = agg_df.select_dtypes(include=['int64', 'float64']).columns
cluster_summary = agg_df.groupby('cluster')[numeric_cols].mean()
print("\nCluster Summary:\n", cluster_summary)

# Map clusters to credit scores (heuristic mapping)
cluster_to_score = {
    0: 850,  # High activity (likely active trader)
    1: 650,  # Moderate usage
    2: 350,  # Low usage / inactive
    3: 150   # Almost no activity
}

agg_df['credit_score'] = agg_df['cluster'].map(cluster_to_score)

# Save final output
agg_df[['userWallet', 'credit_score', 'cluster']].to_csv('wallet_scores.csv', index=False)
print("\nWallet scores saved to 'wallet_scores.csv'")

agg_df[['userWallet', 'cluster', 'credit_score']].to_json(
    'wallet_scores.json', orient='records', indent=2
)

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.hist(agg_df['credit_score'], bins=[0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],
         edgecolor='black')
plt.title('Wallet Credit Score Distribution')
plt.xlabel('Score Range')
plt.ylabel('Number of Wallets')
plt.grid(True)
plt.tight_layout()
plt.savefig("score_distribution.png")
plt.show()

print(agg_df.columns)

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))

# Drop non-numeric columns before computing correlation
corr = agg_df.drop(['userWallet', 'cluster'], axis=1).corr()

sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")

plt.title('Correlation Heatmap of Aggregated Wallet Features', fontsize=16)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
plt.scatter(agg_df['total_volume_eth'], agg_df['credit_score'],
            c=agg_df['cluster'], cmap='viridis', s=60, alpha=0.8, edgecolors='k')
plt.xlabel("Total Volume (ETH)")
plt.ylabel("Credit Score")
plt.title("Wallet Credit Score vs Total Volume (Cluster Colored)", fontsize=16)
plt.colorbar(label="Cluster")
plt.grid(True)
plt.tight_layout()
plt.show()













